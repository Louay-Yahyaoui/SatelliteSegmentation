{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1635643,
          "sourceType": "datasetVersion",
          "datasetId": 966962
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Satellite image segmentation",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the necessary packages"
      ],
      "metadata": {
        "id": "z70_mcMcBZcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "import tensorflow.keras.backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:12.038937Z",
          "iopub.execute_input": "2025-12-25T13:12:12.039472Z",
          "iopub.status.idle": "2025-12-25T13:12:24.404899Z",
          "shell.execute_reply.started": "2025-12-25T13:12:12.039439Z",
          "shell.execute_reply": "2025-12-25T13:12:24.403983Z"
        },
        "trusted": true,
        "id": "qQ5Ro_OXBZcc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:24.406741Z",
          "iopub.execute_input": "2025-12-25T13:12:24.407208Z",
          "iopub.status.idle": "2025-12-25T13:12:24.700144Z",
          "shell.execute_reply.started": "2025-12-25T13:12:24.407177Z",
          "shell.execute_reply": "2025-12-25T13:12:24.699046Z"
        },
        "id": "Yk4uZow2BZcc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and preprocessing images from the DeepGlobe dataset"
      ],
      "metadata": {
        "id": "0YeovdxYBZcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset if not already present.\n",
        "!curl -L -o deepglobe-land-cover-classification-dataset.zip https://www.kaggle.com/api/v1/datasets/download/balraj98/deepglobe-land-cover-classification-dataset\n",
        "!unzip deepglobe-land-cover-classification-dataset.zip -d deepglobe-land-cover-classification-dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:24.701579Z",
          "iopub.execute_input": "2025-12-25T13:12:24.702007Z",
          "iopub.status.idle": "2025-12-25T13:12:24.723719Z",
          "shell.execute_reply.started": "2025-12-25T13:12:24.701948Z",
          "shell.execute_reply": "2025-12-25T13:12:24.723009Z"
        },
        "id": "gVTxg-TDBZcd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(\"deepglobe-land-cover-classification-dataset\")\n",
        "\n",
        "img_shape = (2448, 2448, 3) # Original image shape\n",
        "input_shape = (512, 512, 3) # Model image shape\n",
        "out_shape = (512, 512, 1) # Output mask shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:24.724841Z",
          "iopub.execute_input": "2025-12-25T13:12:24.725451Z",
          "iopub.status.idle": "2025-12-25T13:12:24.732557Z",
          "shell.execute_reply.started": "2025-12-25T13:12:24.725408Z",
          "shell.execute_reply": "2025-12-25T13:12:24.731897Z"
        },
        "trusted": true,
        "id": "BHBHnlCCBZcd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img(img, shape, is_mask = False):\n",
        "    # Images are converted from BGR to RGB.\n",
        "    # Then, their resolution is lowered to accomodate our memory constraints.\n",
        "\n",
        "    image = cv2.resize(cv2.imread(img), shape, interpolation = cv2.INTER_LINEAR if not is_mask else cv2.INTER_NEAREST)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image\n",
        "\n",
        "def preprocess_mask(img, shape):\n",
        "    # Transforming masks from 3 channel to a singular class channel with values from 0 to 6.\n",
        "    mask = np.array(np.round(preprocess_img(img, shape, is_mask = True) / 255.0), dtype = np.uint8)\n",
        "    mask_refined = 4 * mask[:,:,0] + 2 * mask[:,:,1] + mask[:,:,2]\n",
        "    mask_refined = mask_refined * (mask_refined != 7) + 4 * (mask_refined == 7)\n",
        "    return mask_refined\n",
        "\n",
        "def get_dataset(mask_dirs):\n",
        "    # Each mask file is matched to its corresponding satellite image.\n",
        "    sat_dirs = [d.replace(\"_mask.png\", \"_sat.jpg\") for d in mask_dirs]\n",
        "\n",
        "    X = tf.convert_to_tensor([preprocess_img(file, input_shape[:2]) for file in sat_dirs], dtype=tf.uint8)\n",
        "    y = tf.convert_to_tensor([preprocess_mask(file, out_shape[:2]) for file in mask_dirs], dtype=tf.uint8)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:24.735008Z",
          "iopub.execute_input": "2025-12-25T13:12:24.735486Z",
          "iopub.status.idle": "2025-12-25T13:12:24.743839Z",
          "shell.execute_reply.started": "2025-12-25T13:12:24.735458Z",
          "shell.execute_reply": "2025-12-25T13:12:24.74321Z"
        },
        "trusted": true,
        "id": "_TmCv_hVBZcd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the labeled data.\n",
        "train_path = os.path.join(path, \"train\")\n",
        "mask_dirs = glob.glob(os.path.join(train_path,\"*_mask.png\"))\n",
        "\n",
        "n = len(mask_dirs)\n",
        "train_split = 0.9\n",
        "n_train = int(n * train_split)\n",
        "n_val = n - n_train\n",
        "\n",
        "X_train, y_train = get_dataset(mask_dirs[:n_train])\n",
        "print(f\"Loaded {n_train} training images.\")\n",
        "\n",
        "#X_val, y_val = get_dataset(os.path.join(path, \"valid\"))\n",
        "#X_test, y_test = get_dataset(os.path.join(path, \"test\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-12-25T13:12:24.744682Z",
          "iopub.execute_input": "2025-12-25T13:12:24.744924Z",
          "iopub.status.idle": "2025-12-25T13:18:05.850328Z",
          "shell.execute_reply.started": "2025-12-25T13:12:24.744898Z",
          "shell.execute_reply": "2025-12-25T13:18:05.849325Z"
        },
        "trusted": true,
        "id": "u1Z8A3y6BZce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, y_val = get_dataset(mask_dirs[n_train:n])\n",
        "print(f\"Loaded {n_val} validation images.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T13:18:05.851429Z",
          "iopub.execute_input": "2025-12-25T13:18:05.851724Z",
          "iopub.status.idle": "2025-12-25T13:18:42.529908Z",
          "shell.execute_reply.started": "2025-12-25T13:18:05.851697Z",
          "shell.execute_reply": "2025-12-25T13:18:42.528857Z"
        },
        "id": "KhKs1rZUBZce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition"
      ],
      "metadata": {
        "id": "Vs9f-dR6BZce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 consecutive padded convolutions with ReLU activations as outlined in the U-Net paper.\n",
        "# Is the basis for both in the Encoder and the Decoder.\n",
        "\n",
        "class ConvBlock(tf.keras.Layer):\n",
        "    def __init__(self, n_filters, filter_size):\n",
        "        super().__init__()\n",
        "        self.cn1 = tfl.Conv2D(n_filters, filter_size,\n",
        "                            padding = \"same\", use_bias = True)\n",
        "        self.relu1 = tfl.ReLU()\n",
        "        self.bn1 = tfl.BatchNormalization()\n",
        "        self.cn2 = tfl.Conv2D(n_filters, filter_size,\n",
        "                            padding = \"same\", use_bias = True)\n",
        "        self.relu2 = tfl.ReLU()\n",
        "        self.bn2 = tfl.BatchNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.relu1(self.bn1(self.cn1(x)))\n",
        "        x = self.relu2(self.bn2(self.cn2(x)))\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T13:18:42.531121Z",
          "iopub.execute_input": "2025-12-25T13:18:42.531751Z",
          "iopub.status.idle": "2025-12-25T13:18:42.5378Z",
          "shell.execute_reply.started": "2025-12-25T13:18:42.531709Z",
          "shell.execute_reply": "2025-12-25T13:18:42.536883Z"
        },
        "id": "81-ZTZ64BZce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetConv(ConvBlock):\n",
        "    def __init__(self, n_filters, filter_size, pool_stride):\n",
        "        super().__init__(n_filters, filter_size)\n",
        "        # Pooling layer to reduce image resolution.\n",
        "        self.pool = tfl.MaxPooling2D(pool_stride)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = super().call(x)\n",
        "        return x, self.pool(x)\n",
        "\n",
        "\n",
        "class UNetTConv(ConvBlock):\n",
        "    def __init__(self, filters, filter_size, tfilters, tfilter_size):\n",
        "        super().__init__(filters, filter_size)\n",
        "        # ConvTranspose to restore image resolution, should us the same filter size as the pool stride.\n",
        "        self.dcn = tfl.Conv2DTranspose(tfilters, tfilter_size, tfilter_size, padding = \"same\")\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.dcn(super().call(x))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T13:18:42.538893Z",
          "iopub.execute_input": "2025-12-25T13:18:42.539222Z",
          "iopub.status.idle": "2025-12-25T13:18:42.55404Z",
          "shell.execute_reply.started": "2025-12-25T13:18:42.539188Z",
          "shell.execute_reply": "2025-12-25T13:18:42.553264Z"
        },
        "id": "GaTflYv6BZce"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "n_blocks = 4 # Number of encoder and decoder block.\n",
        "log_conv_filters = 5 # Number of filters in the first convolutional layer is 2^log_conv_filters.\n",
        "# Increased by a factor of 2 for each subsequent layer. Inverse order for the decoder.\n",
        "n_classes = 7 # Number of possible classes for each output pixel.\n",
        "filter_size = 3 # Convolution filter size: 3*3\n",
        "tfilter_size = 2 # Transposed convolution filter size: 2*2, should revert the pooling operation.\n",
        "dropout = 0.3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:08.606754Z",
          "iopub.execute_input": "2025-12-25T15:26:08.607569Z",
          "iopub.status.idle": "2025-12-25T15:26:08.611967Z",
          "shell.execute_reply.started": "2025-12-25T15:26:08.607532Z",
          "shell.execute_reply": "2025-12-25T15:26:08.6109Z"
        },
        "id": "RDRhGrAjBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, blocks):\n",
        "        super().__init__()\n",
        "        self.scale = tfl.Rescaling(1.0 / 255.0)\n",
        "        self.convs = [UNetConv(int(2**(log_conv_filters+i)), filter_size, 2) for i in range(blocks)] # encoder\n",
        "        self.dropouts = [tfl.Dropout(dropout) for _ in range(blocks)] # Dropout is used at each decoder step.\n",
        "        self.tconvs = [UNetTConv(int(2**(log_conv_filters + blocks - i)), filter_size,\\\n",
        "                int(2**(log_conv_filters + blocks -i)), tfilter_size) for i in range(blocks)] # decoder\n",
        "\n",
        "        self.convf = ConvBlock(int(2**(log_conv_filters)), filter_size) # Final convolution before classification.\n",
        "        self.conv1x1 =  tfl.Conv2D(n_classes, 1, padding = \"same\") # Convolution across the channels to get 1 probability per class.\n",
        "        # self.softmax = tfl.Softmax(axis = -1)\n",
        "\n",
        "    def call(self, x, training = False):\n",
        "        x = self.scale(x)\n",
        "        xs = []\n",
        "        for conv in self.convs:\n",
        "            # storing the unpooled feature maps for skip connections.\n",
        "            skip, x = conv(x)\n",
        "            xs.append(skip)\n",
        "\n",
        "        skip = None\n",
        "        for tconv, dropout in zip(self.tconvs, self.dropouts):\n",
        "            x = x if skip is None else tf.concat([skip, x], axis = -1)\n",
        "            x = tconv(dropout(x, training = training))\n",
        "            skip = xs.pop()\n",
        "\n",
        "        x = self.convf(tf.concat([skip, x], axis = -1))\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:08.621424Z",
          "iopub.execute_input": "2025-12-25T15:26:08.62194Z",
          "iopub.status.idle": "2025-12-25T15:26:08.631572Z",
          "shell.execute_reply.started": "2025-12-25T15:26:08.621912Z",
          "shell.execute_reply": "2025-12-25T15:26:08.63065Z"
        },
        "id": "YLt9l5LoBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(input_shape)\n",
        "model = UNET(n_blocks)\n",
        "model(inputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:08.633058Z",
          "iopub.execute_input": "2025-12-25T15:26:08.633344Z",
          "iopub.status.idle": "2025-12-25T15:26:09.737606Z",
          "shell.execute_reply.started": "2025-12-25T15:26:08.633318Z",
          "shell.execute_reply": "2025-12-25T15:26:09.736849Z"
        },
        "id": "a1W_jXyxBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "4yv86JPMBZcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1e-9 # To avoid log(0).\n",
        "\n",
        "freqs = np.zeros((n_classes,))\n",
        "for c in range(n_classes):\n",
        "    freqs[c] = np.mean(y_train.numpy() == c)\n",
        "\n",
        "unknown_class = 0\n",
        "beta = 0.1\n",
        "class_weights = (1 - beta) / (1 - beta**freqs)\n",
        "class_weights[unknown_class] = 0.0\n",
        "class_weights = tf.constant(class_weights, dtype = tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def SparseCategoricalCrossentropy(y_true, y_pred):\n",
        "    # y_true = (batch_size, 1) -> one hot (batch_size, n_classes) -> frequency coefficient (each class would have its own weight instead of 1)\n",
        "    y_true = tf.one_hot(tf.reshape(y_true,(-1,)), n_classes) * class_weights # removing the unknown class\n",
        "     # (B, n_classes) * (n_classes,). Broadcasts.\n",
        "    # y_pred = (batch_size, n_classes)\n",
        "    y_pred = tf.reshape(y_pred, (-1, n_classes))\n",
        "    y_pred = y_pred - tf.reduce_max(y_pred, axis = -1, keepdims = True)\n",
        "    log_prob = - tf.math.log(tf.nn.softmax(y_pred, axis = -1) + epsilon)\n",
        "\n",
        "    return tf.reduce_sum(y_true * log_prob) / tf.reduce_sum(tf.cast(y_true, tf.float32))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:09.738628Z",
          "iopub.execute_input": "2025-12-25T15:26:09.738944Z",
          "iopub.status.idle": "2025-12-25T15:26:11.39565Z",
          "shell.execute_reply.started": "2025-12-25T15:26:09.738879Z",
          "shell.execute_reply": "2025-12-25T15:26:11.394649Z"
        },
        "id": "UZSD7VEHBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def DiceLoss(y_true, y_pred):\n",
        "    # Class weights?\n",
        "    y_true = tf.one_hot(tf.reshape(y_true,(-1,)), n_classes)[..., 1:]\n",
        "    y_pred = tf.reshape(y_pred, (-1, n_classes)) [..., 1:]\n",
        "    y_pred = tf.nn.softmax(y_pred, axis = -1)\n",
        "\n",
        "    return 1 - 2 * tf.reduce_sum(y_pred * y_true) / tf.reduce_sum(y_true  + y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.39681Z",
          "iopub.execute_input": "2025-12-25T15:26:11.39713Z",
          "iopub.status.idle": "2025-12-25T15:26:11.40282Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.39707Z",
          "shell.execute_reply": "2025-12-25T15:26:11.401871Z"
        },
        "id": "d8qEHIS4BZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 per class is used as the evaluation metric.\n",
        "f1 = tf.keras.metrics.F1Score(average = \"weighted\")\n",
        "@tf.function\n",
        "def f1_score_images(y_true, y_pred):\n",
        "    # Includes empty class.\n",
        "    f1.reset_state()\n",
        "    y_true_flat = tf.one_hot(tf.reshape(y_true,(-1,)), n_classes)\n",
        "    y_pred_flat = tf.one_hot(tf.reshape(tf.argmax(y_pred, axis = -1), (-1,)), n_classes)\n",
        "    return f1(y_true_flat, y_pred_flat)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.405046Z",
          "iopub.execute_input": "2025-12-25T15:26:11.405344Z",
          "iopub.status.idle": "2025-12-25T15:26:11.415165Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.405317Z",
          "shell.execute_reply": "2025-12-25T15:26:11.414452Z"
        },
        "id": "E4KJOiotBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def IoU(y_true, y_pred):\n",
        "    y_true = tf.one_hot(tf.reshape(y_true, (-1,)), n_classes)\n",
        "    y_pred = tf.one_hot(tf.reshape(tf.argmax(y_pred, axis = -1), (-1,)), n_classes)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true + y_pred) - intersection\n",
        "    return intersection / union"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.427052Z",
          "iopub.execute_input": "2025-12-25T15:26:11.427359Z",
          "iopub.status.idle": "2025-12-25T15:26:11.439248Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.427312Z",
          "shell.execute_reply": "2025-12-25T15:26:11.438507Z"
        },
        "id": "uzG1SoWpBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 3e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    lr,\n",
        "    decay_steps=500,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "#DiceLoss #tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, ignore_class = 0) #SparseCategoricalCrossentropy\n",
        "loss_fn = DiceLoss\n",
        "optimizer = tf.keras.optimizers.AdamW(lr_schedule)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.440141Z",
          "iopub.execute_input": "2025-12-25T15:26:11.440383Z",
          "iopub.status.idle": "2025-12-25T15:26:11.452211Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.440358Z",
          "shell.execute_reply": "2025-12-25T15:26:11.451383Z"
        },
        "id": "_46lnEomBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(X, y, t = 0.2, r = 20.0):\n",
        "    # Translation.\n",
        "    dy = tf.random.uniform([], -t, t) * input_shape[0]\n",
        "    dx = tf.random.uniform([], -t, t) * input_shape[1]\n",
        "\n",
        "    translation_matrix = tf.convert_to_tensor([[1, 0, -dx],\n",
        "                                            [0, 1, -dy],\n",
        "                                            [0, 0, 1]], dtype=tf.float32)\n",
        "\n",
        "    # Rotation.\n",
        "    rotation_angle = (tf.random.uniform([], -r, r)) * np.pi / 180.0\n",
        "    cos = tf.cos(rotation_angle)\n",
        "    sin = tf.sin(rotation_angle)\n",
        "    rotation_matrix = tf.convert_to_tensor([[cos, -sin, 0],\n",
        "                                        [sin, cos, 0],\n",
        "                                        [0, 0, 1]], dtype=tf.float32)\n",
        "\n",
        "    # First 6 entries of 3x3 matrix are the affine parameters, 7th and 8th should just be 0.\n",
        "    transform_matrix = tf.cast(rotation_matrix @ translation_matrix, tf.float32)\n",
        "    transform_params = tf.reshape(transform_matrix, (1, 9))[:, :8]\n",
        "\n",
        "    X = tf.keras.ops.image.affine_transform(\n",
        "    X,\n",
        "    transform_params,\n",
        "    interpolation='nearest',\n",
        "    fill_mode='nearest',\n",
        "    data_format='channels_last'\n",
        "    )\n",
        "\n",
        "    y  = tf.keras.ops.image.affine_transform(\n",
        "    tf.expand_dims(y, axis = -1),\n",
        "    transform_params,\n",
        "    interpolation='nearest',\n",
        "    fill_mode='nearest',\n",
        "    data_format='channels_last'\n",
        "    )\n",
        "\n",
        "    return X, tf.squeeze(y, axis = -1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.45318Z",
          "iopub.execute_input": "2025-12-25T15:26:11.453397Z",
          "iopub.status.idle": "2025-12-25T15:26:11.462601Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.453374Z",
          "shell.execute_reply": "2025-12-25T15:26:11.46173Z"
        },
        "id": "ur8LycRWBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0.2 # translation factor\n",
        "r = 0.0 # maximum absolute rotation angle\n",
        "\n",
        "@tf.function\n",
        "def train_step(X, y):\n",
        "    X, y = augment_image(X, y, t, r)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        preds = model(X, training = True)\n",
        "        loss = loss_fn(y, preds)\n",
        "    f1_score = f1_score_images(y, preds)\n",
        "    iou = IoU(y, preds)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return loss, f1_score, iou"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.463693Z",
          "iopub.execute_input": "2025-12-25T15:26:11.463986Z",
          "iopub.status.idle": "2025-12-25T15:26:11.562145Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.46396Z",
          "shell.execute_reply": "2025-12-25T15:26:11.56114Z"
        },
        "id": "22H3-fFrBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def val_step(X, y):\n",
        "    preds = model(X, training = False)\n",
        "    loss = loss_fn(y, preds)\n",
        "    f1_score = f1_score_images(y, preds)\n",
        "    iou = IoU(y, preds)\n",
        "    return loss, f1_score, iou"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.568519Z",
          "iopub.execute_input": "2025-12-25T15:26:11.568783Z",
          "iopub.status.idle": "2025-12-25T15:26:11.58688Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.568758Z",
          "shell.execute_reply": "2025-12-25T15:26:11.586Z"
        },
        "id": "x12H2fzSBZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "history = {}\n",
        "batch_size = 8\n",
        "EPOCHS = 50\n",
        "best_ckpt = 1.0\n",
        "\n",
        "# tqdm logs to stderr by default.\n",
        "stderr = sys.stderr\n",
        "sys.stderr = sys.stdout\n",
        "checkpoint_path = './best.weights.h5'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:26:11.589658Z",
          "iopub.execute_input": "2025-12-25T15:26:11.590056Z",
          "iopub.status.idle": "2025-12-25T15:26:11.600743Z",
          "shell.execute_reply.started": "2025-12-25T15:26:11.590011Z",
          "shell.execute_reply": "2025-12-25T15:26:11.599974Z"
        },
        "id": "qIBVZvO-BZcf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    # Training loop\n",
        "    train_loss, train_f1, train_iou = 0, 0, 0\n",
        "\n",
        "    for i in tqdm(range(0, X_train.shape[0], batch_size)):\n",
        "        X_batch = X_train[i: i + batch_size]\n",
        "        y_batch = y_train[i: i + batch_size]\n",
        "        loss, f1_score, iou = train_step(X_batch, y_batch)\n",
        "        train_loss += loss * X_batch.shape[0]\n",
        "        train_f1 += f1_score * X_batch.shape[0]\n",
        "        train_iou += iou * X_batch.shape[0]\n",
        "\n",
        "    train_loss /= n_train\n",
        "    train_f1 /= n_train\n",
        "    train_iou /= n_train\n",
        "\n",
        "    history[\"loss\"] = history.get(\"loss\", []) + [train_loss]\n",
        "    history[\"f1\"] = history.get(\"f1\", []) + [train_f1]\n",
        "\n",
        "    val_loss, val_f1, val_iou = 0, 0, 0\n",
        "\n",
        "    for j in range(0, X_val.shape[0], batch_size):\n",
        "        X_batch_val = X_val[j: j + batch_size]\n",
        "        y_batch_val = y_val[j: j + batch_size]\n",
        "        loss, f1_score, iou = val_step(X_batch_val, y_batch_val)\n",
        "        val_loss += loss * X_batch_val.shape[0]\n",
        "        val_f1 += f1_score * X_batch_val.shape[0]\n",
        "        val_iou += iou * X_batch_val.shape[0]\n",
        "\n",
        "    val_loss /= n_val\n",
        "    val_f1 /= n_val\n",
        "    val_iou /= n_val\n",
        "\n",
        "    if val_loss < best_ckpt:\n",
        "        model.save_weights(checkpoint_path)\n",
        "        best_ckpt = val_loss\n",
        "\n",
        "    history[\"val_loss\"] = history.get(\"val_loss\", []) + [val_loss]\n",
        "    history[\"val_f1\"] = history.get(\"val_f1\", []) + [val_f1]\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} / {EPOCHS} loss: {train_loss:0.4f}, F1: {train_f1:0.4f}, IoU: {train_iou:0.4f} val_loss: {val_loss:0.4f}, val_f1: {val_f1:0.4f}, val IoU: {val_iou:0.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:55:58.588342Z",
          "iopub.execute_input": "2025-12-25T15:55:58.588689Z",
          "iopub.status.idle": "2025-12-25T16:00:49.907964Z",
          "shell.execute_reply.started": "2025-12-25T15:55:58.588659Z",
          "shell.execute_reply": "2025-12-25T16:00:49.907047Z"
        },
        "id": "iNyoS-57BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# We reconfigure stderr to default\n",
        "sys.stderr = stderr\n",
        "\n",
        "# Reload the best scoring model.\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:35.062183Z",
          "iopub.execute_input": "2025-12-25T15:52:35.062563Z",
          "iopub.status.idle": "2025-12-25T15:52:35.208226Z",
          "shell.execute_reply.started": "2025-12-25T15:52:35.062533Z",
          "shell.execute_reply": "2025-12-25T15:52:35.207346Z"
        },
        "id": "qF4WSM-6BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"loss\"], label = \"Training loss\")\n",
        "plt.plot(history[\"val_loss\"], label = \"Validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Crossentropy loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:35.209725Z",
          "iopub.execute_input": "2025-12-25T15:52:35.209991Z",
          "iopub.status.idle": "2025-12-25T15:52:35.425288Z",
          "shell.execute_reply.started": "2025-12-25T15:52:35.209963Z",
          "shell.execute_reply": "2025-12-25T15:52:35.424404Z"
        },
        "id": "o3uqE_RPBZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history[\"f1\"], label = \"Training F1\")\n",
        "plt.plot(history[\"val_f1\"], label = \"Validation F1\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Macro F1 Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:35.426621Z",
          "iopub.execute_input": "2025-12-25T15:52:35.427335Z",
          "iopub.status.idle": "2025-12-25T15:52:35.562357Z",
          "shell.execute_reply.started": "2025-12-25T15:52:35.427291Z",
          "shell.execute_reply": "2025-12-25T15:52:35.56145Z"
        },
        "id": "uo9Hwxl7BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "gw-9rG6BBZcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_mask(X_target):\n",
        "    if len(X_target.shape) == 3:\n",
        "        # Add batch dimension\n",
        "        X_target = tf.reshape(X_target, (1,) + X_target.shape)\n",
        "\n",
        "    y_pred = tf.argmax(model(X_target), axis = -1)[0]\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:36.361164Z",
          "iopub.execute_input": "2025-12-25T15:52:36.361416Z",
          "iopub.status.idle": "2025-12-25T15:52:36.366356Z",
          "shell.execute_reply.started": "2025-12-25T15:52:36.361392Z",
          "shell.execute_reply": "2025-12-25T15:52:36.365397Z"
        },
        "id": "7_7BqI6_BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def to_img(y):\n",
        "    \"\"\"Convert class mask back to image for visualization.\"\"\"\n",
        "    out = np.zeros(y.shape[:2] + (3,))\n",
        "\n",
        "    out[:, :, 0] = (y // 4)\n",
        "    out[:, :, 1] = ((y % 4) // 2)\n",
        "    out[:, :, 2] = (y % 2)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:36.367583Z",
          "iopub.execute_input": "2025-12-25T15:52:36.368269Z",
          "iopub.status.idle": "2025-12-25T15:52:36.375629Z",
          "shell.execute_reply.started": "2025-12-25T15:52:36.368227Z",
          "shell.execute_reply": "2025-12-25T15:52:36.374882Z"
        },
        "id": "bUa-MedrBZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix_show(cm):\n",
        "    class_labels = list(range(n_classes))\n",
        "    sns.heatmap(cm,\n",
        "                annot=True,\n",
        "                fmt='g',\n",
        "                cmap='Blues',\n",
        "                xticklabels=class_labels,\n",
        "                yticklabels=class_labels)\n",
        "\n",
        "    plt.ylabel('Actual', fontsize=13)\n",
        "    plt.title('Confusion Matrix', fontsize=17, pad=20)\n",
        "    plt.gca().xaxis.set_label_position('top')\n",
        "    plt.xlabel('Prediction', fontsize=13)\n",
        "    plt.gca().xaxis.tick_top()\n",
        "\n",
        "    plt.gca().figure.subplots_adjust(bottom=0.2)\n",
        "    plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T15:52:36.376701Z",
          "iopub.execute_input": "2025-12-25T15:52:36.37712Z",
          "iopub.status.idle": "2025-12-25T15:52:36.388681Z",
          "shell.execute_reply.started": "2025-12-25T15:52:36.377059Z",
          "shell.execute_reply": "2025-12-25T15:52:36.387892Z"
        },
        "id": "ovAfRnV-BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def Visualize_output(X_target, y_target):\n",
        "    y_pred = predict_mask(X_target)\n",
        "    img_pred = to_img(y_pred)\n",
        "    img_real = to_img(y_target)\n",
        "\n",
        "    y_target_flat = tf.reshape(y_target,-1)\n",
        "    y_pred_flat = tf.reshape(y_pred, -1)\n",
        "\n",
        "    cm = confusion_matrix(y_target_flat, y_pred_flat, labels = np.arange(n_classes))\n",
        "    confusion_matrix_show(cm)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "    # Plot real image\n",
        "    axes[0].imshow(X_target, interpolation = 'nearest')\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(\"Real Image:\")\n",
        "\n",
        "    # Plot predicted mask\n",
        "    axes[1].imshow(img_pred, interpolation = 'nearest')\n",
        "    axes[1].axis('off')\n",
        "    f1.reset_state()\n",
        "    axes[1].set_title(f\"Predicted Mask (F1: {f1(tf.one_hot(y_target_flat, n_classes), tf.one_hot(y_pred_flat, n_classes)):0.4f}):\")\n",
        "\n",
        "    # Plot target mask\n",
        "    axes[2].imshow(img_real, interpolation = 'nearest')\n",
        "    axes[2].axis('off')\n",
        "    axes[2].set_title(\"Real Mask:\")\n",
        "\n",
        "    # Display the images\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T16:02:54.206606Z",
          "iopub.execute_input": "2025-12-25T16:02:54.207335Z",
          "iopub.status.idle": "2025-12-25T16:02:54.214062Z",
          "shell.execute_reply.started": "2025-12-25T16:02:54.207298Z",
          "shell.execute_reply": "2025-12-25T16:02:54.213135Z"
        },
        "id": "6CWKCLQ8BZcg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "random_indices = np.random.randint(0, n_val, 3)\n",
        "for i in random_indices:\n",
        "    Visualize_output(X_val[i], y_val[i])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-25T16:02:56.537246Z",
          "iopub.execute_input": "2025-12-25T16:02:56.537589Z",
          "iopub.status.idle": "2025-12-25T16:02:59.402098Z",
          "shell.execute_reply.started": "2025-12-25T16:02:56.53756Z",
          "shell.execute_reply": "2025-12-25T16:02:59.401184Z"
        },
        "id": "_Asmis0oBZcg"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}